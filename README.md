# Algo Prediction

## ğŸ“‹ Project Overview

**Algo Prediction** est une implÃ©mentation Python de l'algorithme R `predictive_consumption_modelisation` dÃ©veloppÃ© par Energisme pour la modÃ©lisation prÃ©dictive de consommation Ã©nergÃ©tique des bÃ¢timents, conÃ§u pour Ãªtre dÃ©ployÃ© sur Azure Function App.

Le service prend en entrÃ©e un identifiant de bÃ¢timent et deux pÃ©riodes : une pÃ©riode de rÃ©fÃ©rence (donnÃ©es historiques) et une pÃ©riode de prÃ©diction. Il rÃ©cupÃ¨re automatiquement depuis Azure Data Lake Storage (ADLS) les factures Ã©nergÃ©tiques, les DegrÃ©s-Jours UnifiÃ©s (DJU) de la station mÃ©tÃ©o associÃ©e, et les Ã©ventuels facteurs d'influence (occupation, surface, etc.).

L'algorithme original, Ã©crit en R, utilise les donnÃ©es historiques de facturation Ã©nergÃ©tique (gaz, Ã©lectricitÃ©) combinÃ©es aux DegrÃ©s-Jours UnifiÃ©s (DJU) pour construire un modÃ¨le de rÃ©gression linÃ©aire capable de prÃ©dire les consommations futures. Cette version Python a Ã©tÃ© conÃ§ue pour reproduire fidÃ¨lement le comportement de l'algorithme R, fonction par fonction, afin de garantir des rÃ©sultats identiques tout en permettant un dÃ©ploiement cloud-native sur Azure Function App. Chaque Ã©tape du pipeline R a son Ã©quivalent Python documentÃ©, avec une attention particuliÃ¨re portÃ©e aux dÃ©tails d'implÃ©mentation.

Les rÃ©sultats (prÃ©dictions mensuelles, coefficients du modÃ¨le, mÃ©triques de performance, outliers dÃ©tectÃ©s) sont persistÃ©s en format Parquet sur ADLS et retournÃ©s en JSON via l'API HTTP.

---

## ğŸ“ Repository Structure

```
algo_prediction/
â”‚
â”œâ”€â”€ domain.py                    # Dataclasses RequestParams, SiteInfo
â”œâ”€â”€ config.py                    # Variables d'environnement ADLS
â”‚
â”œâ”€â”€ algo_services/
â”‚   â””â”€â”€ run_algo_services.py     # Pipeline principal (â‰ˆ R: predictive_consumption_modelisation)
â”‚
â”œâ”€â”€ backend_gestion/
â”‚   â”œâ”€â”€ base.py                  # Interface abstraite BackendBase
â”‚   â”œâ”€â”€ adls_silver.py           # Lecture/Ã©criture ADLS Parquet
â”‚   â””â”€â”€ silver_results_writer.py # Persistance rÃ©sultats (predictions, models)
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ invoices.py              # AgrÃ©gation mensuelle factures (â‰ˆ R: prorata processing)
â”‚   â”œâ”€â”€ months.py                # GÃ©nÃ©ration liste month_year (â‰ˆ R: month_year_invoice)
â”‚   â”œâ”€â”€ dju.py                   # RÃ©cupÃ©ration DJU mensuels (â‰ˆ R: retrieve_dju_data)
â”‚   â”œâ”€â”€ usage_data.py            # Pivot facteurs d'usage (â‰ˆ R: retrieve_influencing_factor)
â”‚   â””â”€â”€ model_table.py           # Construction table modÃ¨le + split train/test (â‰ˆ R: index_ref)
â”‚
â””â”€â”€ modeling/
    â”œâ”€â”€ status.py                # Enum TrainStatus (NO_DATA, TOO_FEW, OK)
    â”œâ”€â”€ decision.py              # StratÃ©gie d'entraÃ®nement (â‰ˆ R: control missing/zero data)
    â”œâ”€â”€ imputation.py            # Imputation valeurs manquantes (â‰ˆ R: ranking_method)
    â”œâ”€â”€ outliers.py              # DÃ©tection anomalies (â‰ˆ R: ts_anomaly_detection)
    â”œâ”€â”€ postprocess.py           # Pipeline Y: missing â†’ outliers â†’ best Y (â‰ˆ R: lignes 1160-1268)
    â”œâ”€â”€ dju_model.py             # RÃ©gression DJU + sÃ©lection HDD/CDD (â‰ˆ R: lm + which.max)
    â”œâ”€â”€ mean_model.py            # ModÃ¨le moyenne simple si n < 6 (â‰ˆ R: note_001 branch)
    â”œâ”€â”€ metrics.py               # MÃ©triques rÃ©gression (â‰ˆ R: forecast::accuracy)
    â””â”€â”€ training.py              # Orchestration entraÃ®nement (â‰ˆ R: boucle fluid/pdl)
```

---

## ğŸ—ï¸ Architecture du Code

### Vue Globale

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Azure Function    â”‚
                                    â”‚   HTTP Trigger      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         algo_services/run_algo_services.py                   â”‚
â”‚                         run_building_and_persist()                           â”‚
â”‚                         Point d'entrÃ©e principal                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                           â”‚                           â”‚
           â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  backend_gestion/   â”‚    â”‚   preprocessing/    â”‚    â”‚     modeling/       â”‚
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â”‚  â€¢ adls_silver.py   â”‚â”€â”€â”€â–¶â”‚  â€¢ invoices.py      â”‚â”€â”€â”€â–¶â”‚  â€¢ training.py      â”‚
â”‚  â€¢ silver_results_  â”‚    â”‚  â€¢ dju.py           â”‚    â”‚  â€¢ postprocess.py   â”‚
â”‚    writer.py        â”‚â—€â”€â”€â”€â”‚  â€¢ usage_data.py    â”‚    â”‚  â€¢ outliers.py      â”‚
â”‚                     â”‚    â”‚  â€¢ model_table.py   â”‚    â”‚  â€¢ dju_model.py     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                                     â”‚
           â–¼                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ADLS Gen2        â”‚                               â”‚   JSON Response     â”‚
â”‚    (Parquet)        â”‚                               â”‚   (API Output)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              INPUT                                          â”‚
â”‚  building_id, start_ref, end_ref, start_pred, end_pred                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         1. DATA RETRIEVAL                                   â”‚
â”‚  backend_gestion/adls_silver.py                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  get_site_info()      â†’ Infos bÃ¢timent + station mÃ©tÃ©o                     â”‚
â”‚  get_invoices()       â†’ Factures brutes                                    â”‚
â”‚  get_usage_data()     â†’ Facteurs d'usage                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         2. PREPROCESSING                                    â”‚
â”‚  preprocessing/                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  build_monthly_invoices()           â†’ AgrÃ©gation mensuelle                 â”‚
â”‚  get_degreedays_mentuel()           â†’ DJU par station                      â”‚
â”‚  build_monthly_usage_factors()      â†’ Pivot facteurs                       â”‚
â”‚  build_model_table_for_pdl_fluid()  â†’ Table finale                         â”‚
â”‚  split_train_test_like_r()          â†’ SÃ©paration train/test                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         3. MODELING                                         â”‚
â”‚  modeling/                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  train_like_r()                                                      â”‚  â”‚
â”‚  â”‚  Orchestration principale                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                         â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚          â–¼                       â–¼                       â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ decision.py   â”‚     â”‚ postprocess.py  â”‚     â”‚ dju_model.py    â”‚        â”‚
â”‚  â”‚ StratÃ©gie     â”‚     â”‚ build_y_like_r  â”‚     â”‚ RÃ©gression      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                 â”‚                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                    â–¼                         â–¼                             â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚           â”‚ imputation.py â”‚        â”‚  outliers.py    â”‚                     â”‚
â”‚           â”‚ ranking_methodâ”‚        â”‚ ts_anomaly_     â”‚                     â”‚
â”‚           â”‚ _like_r()     â”‚        â”‚ detection_like_râ”‚                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         4. OUTPUT                                           â”‚
â”‚  backend_gestion/silver_results_writer.py                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  persist_predictions_monthly()  â†’ Parquet predictions                      â”‚
â”‚  persist_models()               â†’ Parquet models                           â”‚
â”‚                                                                            â”‚
â”‚  Return JSON: results, models, outliers_details, outliers_notes            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DÃ©pendances entre Modules

```
training.py
    â”œâ”€â”€ decision.py          (decide_training_strategy_like_r)
    â”œâ”€â”€ postprocess.py       (build_y_like_r)
    â”‚       â”œâ”€â”€ imputation.py    (ranking_method_like_r)
    â”‚       â”œâ”€â”€ outliers.py      (ts_anomaly_detection_like_r)
    â”‚       â””â”€â”€ dju_model.py     (r2_and_adj_r2)
    â”œâ”€â”€ dju_model.py         (run_best_dju_model_like_r, choose_best_hdd_cdd_like_r)
    â”‚       â””â”€â”€ metrics.py       (regression_metrics)
    â””â”€â”€ mean_model.py        (run_mean_model_like_r)
```

### Boucle Principale (run_building_and_persist)

```
Pour chaque PDL (point de livraison):
    Pour chaque FLUID (gaz, elec, ...):
        â”‚
        â”œâ”€â”€ 1. Filtrer factures pour ce PDL + FLUID
        â”œâ”€â”€ 2. Construire model_table (factures + DJU + usage)
        â”œâ”€â”€ 3. Split train / test
        â”œâ”€â”€ 4. train_like_r()
        â”‚       â”œâ”€â”€ Si NO_DATA        â†’ skip
        â”‚       â”œâ”€â”€ Si TOO_FEW (n<6)  â†’ mean_model
        â”‚       â””â”€â”€ Si OK             â†’ postprocess + dju_model
        â”œâ”€â”€ 5. Collecter predictions + model_coefficients + outliers
        â””â”€â”€ 6. Append aux rÃ©sultats globaux

Persister rÃ©sultats ADLS
Retourner JSON
```

---

## ğŸ“¦ Requirements

```txt
# Core Data
pandas>=2.0.0
numpy>=1.24.0
pyarrow>=14.0.0

# Azure
azure-functions>=1.17.0
azure-storage-file-datalake>=12.14.0
azure-identity>=1.15.0

# Statistical / Modeling
statsmodels>=0.14.0
scipy>=1.11.0

# Date utilities
python-dateutil>=2.8.0
```

---

## âš™ï¸ Configuration

### Variables d'Environnement

| Variable | Description |
|----------|-------------|
| `ADLS_ACCOUNT_NAME` | Nom du compte Azure Data Lake Storage |
| `ADLS_ACCOUNT_KEY` | ClÃ© d'accÃ¨s au compte ADLS |
| `ADLS_CONTAINER_NAME` | Nom du container ADLS |

### Sources de DonnÃ©es ADLS (Silver)

| Chemin | Description |
|--------|-------------|
| `silver/building/building.parquet` | Infos bÃ¢timents (station mÃ©tÃ©o) |
| `silver/deliverypoint/deliverypoint.parquet` | Points de livraison |
| `silver/invoice/invoice.parquet` | Factures Ã©nergÃ©tiques |
| `silver/degreedays/degreedays_monthly.parquet` | DJU mensuels |
| `silver/usage_data/usage_data.parquet` | Facteurs d'usage |

---

## ğŸš€ Usage

### Appel Direct (Python)

```python
from datetime import date
from algo_prediction.algo_services.run_algo_services import run_building_and_persist

result = run_building_and_persist(
    building_id="BUILDING_001",
    start_ref=date(2022, 1, 1),
    end_ref=date(2024, 12, 31),
    start_pred=date(2025, 1, 1),
    end_pred=date(2025, 12, 31),
)
```

### Appel API (HTTP)

```bash
curl -X POST "https://<function-app>.azurewebsites.net/api/predict" \
  -H "Content-Type: application/json" \
  -H "x-functions-key: <YOUR_KEY>" \
  -d '{
    "building_id": "BUILDING_001",
    "start_ref": "2022-01-01",
    "end_ref": "2024-12-31",
    "start_pred": "2025-01-01",
    "end_pred": "2025-12-31"
  }'
```

### RÃ©ponse

```json
{
  "id_building_primaire": "BUILDING_001",
  "run_id": "a1b2c3d4-...",
  "created_at": "2025-02-11T10:30:00+00:00",
  "results": [
    {
      "deliverypoint_id_primaire": "PDL_001",
      "fluid": "GAZ",
      "month_str": "2025-01",
      "real_consumption": null,
      "predictive_consumption": 12500.5,
      "confidence_lower95": 10200.3,
      "confidence_upper95": 14800.7
    }
  ],
  "models": [
    {
      "deliverypoint_id_primaire": "PDL_001",
      "fluid": "GAZ",
      "chosen_hdd": "hdd18",
      "chosen_cdd": null,
      "b_coefficient": 1500.2,
      "a_hdd": 45.3,
      "adjR2": 0.92
    }
  ],
  "outliers_details": [...],
  "outliers_notes": [...]
}
```

---

## ğŸ”— Correspondance R / Python

### Pipeline Principal

| R (`predictive_consumption_modelisation`) | Python (`run_building_and_persist`) |
|-------------------------------------------|-------------------------------------|
| `for (fluid in fluids) { for (pdl in pdls) {...} }` | `for pdl_id in pdls: for fluid in fluids:` |
| `retrieve_invoice` â†’ GET backend | `backend.get_invoices()` â†’ ADLS Parquet |
| `retrieve_dju_data` â†’ GET backend | `get_degreedays_mentuel()` â†’ ADLS Parquet |
| `retrieve_influencing_factor` â†’ GET backend | `build_monthly_usage_factors()` â†’ ADLS Parquet |
| `index_ref <- which(start >= start_ref & end <= end_ref)` | `split_train_test_like_r()` |
| `train <- data.frame(retrieve_invoice[index_ref, ])` | `train, test = split_train_test_like_r(...)` |

---

### SÃ©lection Optimal DJU

| R (lignes 1143-1158) | Python (`choose_best_hdd_cdd_like_r`) |
|----------------------|---------------------------------------|
| `accuracy_dju_hdd <- sapply(dju_ref_hdd, function(x){` | `for col in hdd_cols:` |
| `  model <- summary(lm(invoice.consumption ~ x, data=train))` | `  _, adj = r2_and_adj_r2(y, X @ beta, p)` |
| `  model$adj.r.squared` | `  hdd_scores[col] = adj` |
| `})` | |
| `names(which.max(accuracy_dju_hdd))` | `best_hdd = max(hdd_scores, key=hdd_scores.get)` |

---

### Traitement Valeurs Manquantes

| R (lignes 1160-1190) | Python (`build_y_like_r` + `ranking_method_like_r`) |
|----------------------|-----------------------------------------------------|
| `number_of_gaps <- sum(is.na(train$invoice.consumption))/nrow(train)` | `gap_ratio = df["is_missing"].mean()` |
| `if (number_of_gaps >= 0.2) { note_003 }` | `if gap_ratio >= 0.2: messages.append("note_003...")` |
| `train$is_missing <- is.na(train$invoice.consumption)` | `df["is_missing"] = y_raw.isna()` |
| `if (sum(train$is_missing) != 0) { note_004 }` | `if df["is_missing"].sum() > 0: messages.append("note_004...")` |

#### ranking_method

| R (`ranking_method`, lignes 448-475) | Python (`ranking_method_like_r`) |
|--------------------------------------|----------------------------------|
| `linear_interpolation <- interpolation_missing(x, "linear")` | `linear = interpolation_missing_linear(s)` |
| `Kalman_StructTS <- na_Kalman_Smooth(x, "StructTS")` | `kalman = kalman_smooth_structts_like(s)` |
| `if (period > 1 && length(x) > 2*period) {` | `if period > 1 and len(s) > 2 * period:` |
| `  season_stl_loess <- forecast::na.interp(x)` | `  season = seasonal_stl_loess_like(s, period)` |
| `}` | |
| `weighted_combination <- rowMeans(combination)` | `df["weighted_combination"] = df.mean(axis=1)` |

#### Refit DJU sur Missing

| R (lignes 1182-1183) | Python (`_predict_dju_fitted`) |
|----------------------|--------------------------------|
| `fit <- lm(consumption_imputation ~ HDD + CDD, data=train)` | `beta = np.linalg.lstsq(X_fit, y_fit)` |
| `train$consumption_imputation[is_missing] <- fit$fitted.values[is_missing]` | `df.loc[is_missing, "consumption_imputation"] = fitted[is_missing]` |

---

### DÃ©tection Outliers

| R (`ts_anomaly_detection`, lignes 382-434) | Python (`ts_anomaly_detection_like_r`) |
|--------------------------------------------|----------------------------------------|
| `n <- length(x)` | `n = len(x)` |
| `freq <- frequency(x)` | `period = 12` |
| `if (nmiss > 0) { xx <- forecast::na.interp(x) }` | `xx = _na_interp_ts_like(x, period)` |
| `if (freq > 1 && n > 2*freq) {` | `if period > 1 and n > 2 * period:` |
| `  fit <- forecast::mstl(xx, robust=TRUE)` | `  stl = STL(xx, period, robust=True).fit()` |
| `  strength <- 1 - var(rem)/var(detrend)` | `  strength = 1 - var(rem) / var(detrend)` |
| `  if (strength >= 0.6) { xx <- seasadj(fit) }` | `  if strength >= 0.6: xx = xx - seasonal` |
| `}` | |
| `mod <- supsmu(tt, xx)` | `smooth = lowess(xx, tt, frac=0.25, it=0)` |
| `resid <- xx - mod$y` | `resid = xx - smooth` |
| `resid.q <- quantile(resid, c(0.25, 0.75))` | `q1 = _quantile_type7(resid, 0.25)` |
| `iqr <- diff(resid.q)` | `iqr = q3 - q1` |
| `limits <- resid.q + thres * iqr * c(-1, 1)` | `low = q1 - thres * iqr` ; `high = q3 + thres * iqr` |
| `outliers <- which(resid < limits[1] \| resid > limits[2])` | `out_mask = (resid < low) \| (resid > high)` |
| `if (iterate > 1) { tsoutliers(x, iterate=1) }` | `for pass_num in range(1, iterate + 1):` |

---

### Correction Outliers

| R (lignes 1204-1226) | Python (`build_y_like_r`) |
|----------------------|---------------------------|
| `ts_data <- ts(train$consumption_imputation, frequency=12)` | `res = ts_anomaly_detection_like_r(df["consumption_imputation"])` |
| `anomaly_detection <- ts_anomaly_detection(ts_data, thres=3)` | |
| `train$is_anomaly <- is.na(anomaly_detection$x)` | `df["is_anomaly"] = res.outlier_mask` |
| `if (sum(train$is_anomaly) != 0) { note_005 }` | `if out_mask.sum() > 0: messages.append("note_005...")` |
| `ts_data <- ts(anomaly_detection$x, frequency=12)` | `base = df["consumption_imputation"].copy()` |
| `# (x avec NA aux outliers)` | `base.loc[out_mask] = np.nan` |
| `missing_imputation <- ranking_method(ts_data, period=12)` | `corr = ranking_method_like_r(base, period=12)` |
| `train$consumption_correction <- missing_imputation$weighted_combination` | `df["consumption_correction"] = corr["weighted_combination"]` |
| `fit <- lm(consumption_correction ~ HDD + CDD, data=train)` | `fitted = _predict_dju_fitted(df, "consumption_correction", ~is_anomaly)` |
| `train$consumption_correction[is_anomaly] <- fit$fitted.values[is_anomaly]` | `df.loc[is_anomaly, "consumption_correction"] = fitted[is_anomaly]` |

---

### RÃ¨gle des ZÃ©ros

| R (lignes 1235-1258) | Python (`build_y_like_r`) |
|----------------------|---------------------------|
| `train0 <- train[which(train$consumption_imputation != 0),]` | `df_wo0 = df[df["consumption_imputation"] != 0]` |
| `accuracy_ref_invoice0 <- sapply(ref_invoice, ...)` | `s_wo0 = _score_adj_r2(df_wo0, "consumption_imputation")` |
| `accuracy_ref_invoice <- sapply(ref_invoice, ...)` | `s_with0 = _score_adj_r2(df, "consumption_imputation")` |
| `if (accuracy_ref_invoice0[1] >= accuracy_ref_invoice[1]) {` | `if s_wo0 >= s_with0:` |
| `  train <- train0` | `  df = df_wo0` |
| `  note_006: "WITHOUT ZEROS selected"` | `  messages.append("note_006...")` |
| `} else { note_007: "WITH CORRECTED ZEROS selected" }` | `else: messages.append("note_007...")` |

---

### SÃ©lection Best Y

| R (lignes 1261-1268) | Python (`build_y_like_r`) |
|----------------------|---------------------------|
| `ref_invoice <- c("consumption_imputation", "consumption_correction")` | `s_imp = _score_adj_r2(df, "consumption_imputation")` |
| `accuracy_ref_invoice <- sapply(ref_invoice, function(x){` | `s_cor = _score_adj_r2(df, "consumption_correction")` |
| `  model <- summary(lm(x ~ HDD + CDD, data=train))` | |
| `  model$adj.r.squared` | |
| `})` | |
| `names(which.max(accuracy_ref_invoice))` | `best_y = "imputation" if s_imp >= s_cor else "correction"` |
| `note_008: "xxx was selected as the best outcome Y"` | `messages.append("note_008: {best_y} selected...")` |

---

### ModÃ¨le Final & PrÃ©dictions

| R (lignes 1286-1302) | Python (`run_best_dju_model_like_r`) |
|----------------------|--------------------------------------|
| `groupvars <- c(optimal_dju_name, name_influencing_factor)` | `features = [best_hdd, best_cdd] + influencing_cols` |
| `fit <- lm(best_Y ~ groupvars, data=train)` | `beta = np.linalg.lstsq(X_train, y_train)` |
| `model_coefficients <- list(` | `model_coefficients = {` |
| `  a_coefficient = fit$coefficients[-1],` | `  "a_coefficient.hdd": beta[1],` |
| `  b_coefficient = fit$coefficients[1]` | `  "b_coefficient": beta[0]` |
| `)` | `}` |
| `accuracy <- forecast::accuracy(y_true, y_pred)` | `metrics = regression_metrics(y_true, y_pred)` |
| `R2 <- summary(fit)$r.squared` | `r2, adj_r2 = r2_and_adj_r2(y, yhat, p)` |
| `pred <- predict(fit, test, interval="confidence")` | `y_pred = X_test @ beta` |
| `confidence_lower95 = pred$lwr` | `ci = t_crit * se` â†’ `lower = y_pred - ci` |
| `confidence_upper95 = pred$upr` | `upper = y_pred + ci` |

---

### Messages / Notes

| Code R | Code Python | Description |
|--------|-------------|-------------|
| `note_000` | `TrainStatus.NO_REFERENCE_DATA` | Aucune donnÃ©e de rÃ©fÃ©rence |
| `note_001` | `TrainStatus.TOO_FEW_OBSERVATIONS` | Moins de 6 observations â†’ modÃ¨le moyenne |
| `note_003` | `"note_003: MISSING > 20%"` | Plus de 20% de valeurs manquantes |
| `note_004` | `"note_004: MISSING data occurred"` | PrÃ©sence de valeurs manquantes |
| `note_005` | `"note_005: ANOMALIES data occurred"` | Outliers dÃ©tectÃ©s |
| `note_006` | `"note_006: WITHOUT ZEROS selected"` | DonnÃ©es sans zÃ©ros sÃ©lectionnÃ©es |
| `note_007` | `"note_007: WITH CORRECTED ZEROS"` | DonnÃ©es avec zÃ©ros corrigÃ©s |
| `note_008` | `"note_008: {Y} selected as best Y"` | Meilleur Y sÃ©lectionnÃ© |
| `note_009` | `"debug_postprocess_dju: best_hdd=..."` | Meilleur DJU sÃ©lectionnÃ© |

---

### Note sur l'Alignement

L'implÃ©mentation Python reproduit fidÃ¨lement **~95%** du comportement R. La seule diffÃ©rence notable concerne la fonction de lissage dans `ts_anomaly_detection` :

| Aspect | R | Python |
|--------|---|--------|
| Fonction | `supsmu()` | `lowess()` |
| Span | Cross-validation automatique | Fixe: 0.25 (n<40), 0.20 (n<100), 0.15 (nâ‰¥100) |
| ItÃ©rations robustes | Non (supsmu n'en a pas) | `it=0` (dÃ©sactivÃ©es pour matcher R) |

Cette diffÃ©rence peut occasionnellement produire des variations mineures dans la dÃ©tection d'outliers pour les valeurs proches des bornes IQR.
